{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical data loaded from: /Users/vanditgupta/Vandit/Github/Projects/CryptoForecastPro/data/historical_crypto_reddit_merged_historical/merged_crypto_reddit_historical_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_script_dir = os.getcwd()\n",
    "\n",
    "# Define the file path dynamically\n",
    "historical_data_path = os.path.join(current_script_dir, \"..\", \"data\", \"historical_crypto_reddit_merged_historical\", \"merged_crypto_reddit_historical_data.csv\")\n",
    "\n",
    "# Normalize the path for consistency\n",
    "historical_data_path = os.path.normpath(historical_data_path)\n",
    "\n",
    "# Load historical data\n",
    "historical_data = pd.read_csv(historical_data_path)\n",
    "\n",
    "print(f\"Historical data loaded from: {historical_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical data\n",
    "historical_data = pd.read_csv(historical_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Data Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8318 entries, 0 to 8317\n",
      "Data columns (total 22 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Date             8318 non-null   object \n",
      " 1   Symbol           8318 non-null   object \n",
      " 2   Open             8318 non-null   float64\n",
      " 3   High             8318 non-null   float64\n",
      " 4   Low              8318 non-null   float64\n",
      " 5   Close            8318 non-null   float64\n",
      " 6   Sentiment_Score  8318 non-null   float64\n",
      " 7   Score            8318 non-null   int64  \n",
      " 8   Comments         8318 non-null   int64  \n",
      " 9   Title            8318 non-null   object \n",
      " 10  Content          8318 non-null   object \n",
      " 11  Row_Count        8318 non-null   int64  \n",
      " 12  Sentiment_Label  8318 non-null   object \n",
      " 13  Sentiment_Lag_1  8308 non-null   float64\n",
      " 14  Score_Lag_1      8308 non-null   float64\n",
      " 15  Comments_Lag_1   8308 non-null   float64\n",
      " 16  Sentiment_Lag_3  8288 non-null   float64\n",
      " 17  Score_Lag_3      8288 non-null   float64\n",
      " 18  Comments_Lag_3   8288 non-null   float64\n",
      " 19  Sentiment_Lag_7  8248 non-null   float64\n",
      " 20  Score_Lag_7      8248 non-null   float64\n",
      " 21  Comments_Lag_7   8248 non-null   float64\n",
      "dtypes: float64(14), int64(3), object(5)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information\n",
    "print(\"Historical Data Overview:\")\n",
    "print(historical_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Historical Data:\n",
      "Date                0\n",
      "Symbol              0\n",
      "Open                0\n",
      "High                0\n",
      "Low                 0\n",
      "Close               0\n",
      "Sentiment_Score     0\n",
      "Score               0\n",
      "Comments            0\n",
      "Title               0\n",
      "Content             0\n",
      "Row_Count           0\n",
      "Sentiment_Label     0\n",
      "Sentiment_Lag_1    10\n",
      "Score_Lag_1        10\n",
      "Comments_Lag_1     10\n",
      "Sentiment_Lag_3    30\n",
      "Score_Lag_3        30\n",
      "Comments_Lag_3     30\n",
      "Sentiment_Lag_7    70\n",
      "Score_Lag_7        70\n",
      "Comments_Lag_7     70\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Historical Data:\")\n",
    "print(historical_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wr/zc6wwttj521cw_5njq3h828m0000gn/T/ipykernel_76956/1399831779.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  historical_data['Symbol'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "historical_data['Symbol'].fillna('Unknown', inplace=True)\n",
    "historical_data.fillna(0, inplace=True)  # Replace other missing values with 0 for simplicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid Dates in Historical Data:\n",
      "Empty DataFrame\n",
      "Columns: [Date, Symbol, Open, High, Low, Close, Sentiment_Score, Score, Comments, Title, Content, Row_Count, Sentiment_Label, Sentiment_Lag_1, Score_Lag_1, Comments_Lag_1, Sentiment_Lag_3, Score_Lag_3, Comments_Lag_3, Sentiment_Lag_7, Score_Lag_7, Comments_Lag_7]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Validate date column\n",
    "historical_data['Date'] = pd.to_datetime(historical_data['Date'], errors='coerce')\n",
    "print(\"\\nInvalid Dates in Historical Data:\")\n",
    "print(historical_data[historical_data['Date'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric columns are valid\n",
    "numeric_columns = ['Open', 'High', 'Low', 'Close', 'Sentiment_Score', 'Score', 'Comments']\n",
    "for col in numeric_columns:\n",
    "    historical_data[col] = pd.to_numeric(historical_data[col], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with invalid numeric data\n",
    "historical_data.dropna(subset=numeric_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Sentiment_Label contains valid categories\n",
    "valid_labels = ['Positive', 'Neutral', 'Negative']\n",
    "historical_data['Sentiment_Label'] = historical_data['Sentiment_Label'].where(\n",
    "    historical_data['Sentiment_Label'].isin(valid_labels), 'Neutral'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "historical_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned historical data saved to '/Users/vanditgupta/Vandit/Github/Projects/CryptoForecastPro/data/historical_crypto_reddit_merged_historical/cleaned_historical_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Define the output file path dynamically\n",
    "cleaned_historical_data_path = os.path.join(current_script_dir, \"..\", \"data\", \"historical_crypto_reddit_merged_historical\", \"cleaned_historical_data.csv\")\n",
    "\n",
    "# Normalize the path for consistency\n",
    "cleaned_historical_data_path = os.path.normpath(cleaned_historical_data_path)\n",
    "\n",
    "# Save the cleaned historical data\n",
    "historical_data.to_csv(cleaned_historical_data_path, index=False)\n",
    "print(f\"Cleaned historical data saved to '{cleaned_historical_data_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptoforecastpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
